# GNN-Based Preconditioner for Sparse Matrices from r-Process Simulations

This repository contains a custom Graph Neural Network (GNN) developed to predict preconditioners for sparse matrices generated by r-process nucleosynthesis simulations using [SkyNet](https://bitbucket.org/jlippuner/skynet/). The GNN aims to accelerate the solution of large, sparse, and asymmetric linear systems by mimicking the effect of Incomplete LU (ILU)-based preconditioning.

This approach is inspired by recent work in machine learning for scientific computing, particularly:  
- [Jie Chen, 2025](https://arxiv.org/abs/2406.00809), *Graph Neural Preconditioners for Iterative Solutions of Sparse Linear Systems*  
- [Paul HÃ¤usner et al., 2024](https://arxiv.org/abs/2305.16368), *Neural Incomplete Factorization: Learning Preconditioners for the Conjugate Gradient Method*


---

## ðŸš€ Objective

The GNN learns to generate preconditioners directly from the graph representation of a sparse Jacobian matrix. These learned preconditioners are used to enhance the  convergence of iterative solvers like BiCGSTAB, significantly reducing the computational cost of nucleosynthesis simulations.

---

## ðŸ§  Model Overview

- **Input Graphs**: Constructed from CSR-format Jacobians as Coates graphs (directed and weighted).
- **Edge Features**: Z-score normalized matrix values.
- **Node Features**:
  - Position/index
  - Node degree (raw, max, min, mean, variance)
  - Diagonal dominance metrics
  - Right-hand-side vector (RHS)

- **Architecture**:
  - Built using [PyTorch Geometric](https://pytorch-geometric.readthedocs.io/)
  - Custom message-passing layers with `torch.nn.Linear` + LeakyReLU
  - Three-stage architecture: initialization â†’ message passing â†’ edge prediction
  - Output predicts a sparsity pattern and values mimicking ILUT preconditioners

---

## ðŸ“Š Results

- Models trained using ILUT preconditioners generated via custom code and Intel MKL's `dcrilut`.
- Achieves effective post-preconditioning behaviour.
- Integration with iterative solvers significantly reduces residual norms and iteration counts.

---

## ðŸ”§ Applications

- r-process simulations in astrophysics (SkyNet)
- Sparse matrix solvers in scientific computing
- Extendable to CFD, biological systems, and financial modelling

---


